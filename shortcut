1. Git Update:
    git add .
    git commit -m ""
    git push -u origin main

2. Run script:
    python run.py -p train -c config/BCI.json -gpu '2,3'

    nohup python run.py -p train -c config/BCI.json -gpu '2,3' > /dev/null 2>&1&



3. Run tensorboard remotely:
    local: ssh -L 16006:127.0.0.1:6006 ge54xof@172.21.134.105
    remote: tensorboard --logdir experiments/train_BCI_230920_174836/
    local: http://127.0.0.1:16006


 4. Count file numbers
     ls -1 | wc -l


 Some potential ideas:
    change batchnorm to groupnorm or inverse -- donot work
    longer training
    BBDM
    LDM
    Bigger batchsize + random crop + train longer
    delete dropout  -- fine
    Huge batchsize (6*2,crop 224, mse loss, otherwise default):
          MSE loss + crop to 224
            The average psnr is 13.412870116163292
            The average ssim is 0.5150041990810806
    1-ss:
          With new loss and resize to 224
          Numbers:
            The average psnr is 16.569598711078623
            The average ssim is 0.42707161230791724
    Data-Augment:





